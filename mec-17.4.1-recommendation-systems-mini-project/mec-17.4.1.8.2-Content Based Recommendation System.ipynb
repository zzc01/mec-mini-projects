{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KkqlbEEvsHuw"
   },
   "source": [
    "# Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JXCjew2ItepU"
   },
   "source": [
    "Because of computer resource limitation I split the project into 2 notebooks. Here is the 2nd section which concetrates on 8.2: Content Based Recommendation Systems. Most cells of other sections are removed. Here just includes cells that are necessary, for example loading libraries, loading dataset are remained for the use in 8.2.\n",
    "\n",
    "8.2 uses TF_IDF for content based recommendation. The TF-IDF operation creates a huge sparse matrix that consumes a lot of memory. If I integrate 8.2 within the first notebook the jupyter kernel keeps on reseting. That is why 8.2 is extracted and ran in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CL3nuM_Kv17_"
   },
   "source": [
    "## 1. Dataset Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aaic3a2Cw0T5"
   },
   "source": [
    "## 2: Import Necessary Dependencies\n",
    "\n",
    "We will be leveraging __`keras`__ on top of __`tensorflow`__ for building some of the collaborative filtering and hybrid models. There are compatibility issues with handling sparse layers with dense layers till now in TensorFlow 2 hence we are leveraging native Keras but in the long run once this issue is resolved we can leverage __`tf.keras`__ with minimal code updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iX9t8rYaxVGh"
   },
   "outputs": [],
   "source": [
    "# filter out unncessary warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "colab_type": "code",
    "id": "JGWCPwAiP7vv",
    "outputId": "a0320c9e-dfa3-49e3-bf35-2095bce263d8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# To store\\load the data\n",
    "import pandas as pd\n",
    "\n",
    "# To do linear algebra\n",
    "import numpy as np\n",
    "\n",
    "# To create plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# To compute similarities between vectors\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# data load progress bars\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# To create deep learning models\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Embedding, Reshape, Dot, Concatenate, Dense, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "# To stack sparse matrices\n",
    "from scipy.sparse import vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whZc1FgzyPyY"
   },
   "outputs": [],
   "source": [
    "# remove unnecessary TF logs\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Ce2tjPHPzWFd",
    "outputId": "f69dceec-26bc-44a3-b47c-5615a02ded51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version: 1.15.0\n",
      "Keras Version: 2.2.5\n"
     ]
    }
   ],
   "source": [
    "# check keras and TF version used\n",
    "print('TF Version:', tf.__version__)\n",
    "print('Keras Version:', keras.__version__)\n",
    "# TF Version: 1.15.0\n",
    "# Keras Version: 2.2.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lXXYudDD0Coy"
   },
   "source": [
    "Let's start loading data that will be used for building the recommendation systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FJZmUvExOYt"
   },
   "source": [
    "# 3. Load Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AnAU78S7xz-H"
   },
   "source": [
    "## 3.1: Load Movie Metadata Datasets\n",
    "\n",
    "First, we will load the movie_titles.csv data from the Netflix prize data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 242
    },
    "colab_type": "code",
    "id": "WWig4ePBqGSD",
    "outputId": "3dff280d-bb3e-4701-b0fb-ced2eecbee1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape Movie-Metadata:\t(21604, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>original_title</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>The Legend Fong Sai Yuk</th>\n",
       "      <td>This Hong Kong martial-arts extravaganza tells...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Locked Down</th>\n",
       "      <td>Danny, a respected cop, is setup after an inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>There's Only One Jimmy Grimble</th>\n",
       "      <td>Jimmy Grimble is a shy Manchester school boy. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sniper: Reloaded</th>\n",
       "      <td>Brandon Beckett (Collins), the son of the prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dear Frankie</th>\n",
       "      <td>Nine-year-old Frankie and his single mum Lizzi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         overview\n",
       "original_title                                                                   \n",
       "The Legend Fong Sai Yuk         This Hong Kong martial-arts extravaganza tells...\n",
       "Locked Down                     Danny, a respected cop, is setup after an inve...\n",
       "There's Only One Jimmy Grimble  Jimmy Grimble is a shy Manchester school boy. ...\n",
       "Sniper: Reloaded                Brandon Beckett (Collins), the son of the prev...\n",
       "Dear Frankie                    Nine-year-old Frankie and his single mum Lizzi..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a movie metadata dataset\n",
    "movie_metadata = (pd.read_csv('./data/movies_metadata.csv.zip', \n",
    "                              low_memory=False)[['original_title', 'overview', 'vote_count']]\n",
    "                    .set_index('original_title')\n",
    "                    .dropna())\n",
    "\n",
    "# Remove the long tail of rarly rated moves\n",
    "movie_metadata = movie_metadata[movie_metadata['vote_count']>10].drop('vote_count', axis=1)\n",
    "\n",
    "print('Shape Movie-Metadata:\\t{}'.format(movie_metadata.shape))\n",
    "movie_metadata.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dElmRUSWyYoh"
   },
   "source": [
    "Around 21,000 entries in the movies metadata dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wQzTRdm0tYg"
   },
   "source": [
    "# 4. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p5S7Q14L_CL1"
   },
   "source": [
    "# 5. Dimensionality Reduction & Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EI1CoJP9_kbF"
   },
   "source": [
    "# 6. Create Train and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ufn47cGh_wNC"
   },
   "source": [
    "# 7. Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ojO2T5Ti_4TG"
   },
   "source": [
    "# 8. Building Recommendation Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0KRZO1u_24GB"
   },
   "source": [
    "## 8.2: Content Based Recommendation Systems\n",
    "\n",
    "\n",
    "The Content-Based Recommender relies on the similarity of the items being recommended. The basic idea is that if you like an item, then you will also like a “similar” item. It generally works well when it’s easy to determine the context/properties of each item. If there is no historical data for a user or there is reliable metadata for each movie, it can be useful to compare the metadata of the movies to find similar ones.\n",
    "\n",
    "![](./images/Content-based.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WovG-3YFSqo"
   },
   "source": [
    "### Cosine TFIDF Movie Description Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eldw_9lpNfUJ"
   },
   "source": [
    "#### TF-IDF \n",
    "\n",
    "This is a text vectorization technique which is used to determine the relative importance of a document / article / news item / movie etc.\n",
    "\n",
    "TF is simply the frequency of a word in a document. \n",
    "\n",
    "IDF is the inverse of the document frequency among the whole corpus of documents. \n",
    "\n",
    "TF-IDF is used mainly because of two reasons: Suppose we search for “the results of latest European Socccer games” on Google. It is certain that “the” will occur more frequently than “soccer games” but the relative importance of soccer games is higher than the search query point of view. \n",
    "\n",
    "In such cases, TF-IDF weighting negates the effect of high frequency words in determining the importance of an item (document).\n",
    "\n",
    "![](./images/TF-IDF-FORMULA.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Trb9DlZxOYGO"
   },
   "source": [
    "#### Cosine Similarity \n",
    "After calculating TF-IDF scores, how do we determine which items are closer to each other, rather closer to the user profile? This is accomplished using the Vector Space Model which computes the proximity based on the angle between the vectors.\n",
    "\n",
    "Consider the following example\n",
    "\n",
    "![](./images/Vector-space-model.png)\n",
    "\n",
    "Sentence 2 is more likely to be using Term 2 than using Term 1. Vice-versa for Sentence 1. \n",
    "\n",
    "The method of calculating this relative measure is calculated by taking the cosine of the angle between the sentences and the terms. \n",
    "\n",
    "The ultimate reason behind using cosine is that the value of cosine will increase with decreasing value of the angle between which signifies more similarity. \n",
    "\n",
    "The vectors are length normalized after which they become vectors of length 1 and then the cosine calculation is simply the sum-product of vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Cm9mjG-PSr3"
   },
   "source": [
    "In this approch we will use the movie description to create a TFIDF-matrix, which counts and weights words in all descriptions, and compute a cosine similarity between all of those sparse text-vectors. This can easily be extended to more or different features if you like.\n",
    "It is impossible for this model to compute a RMSE score, since the model does not recommend the movies directly.\n",
    "In this way it is possible to find movies closly related to each other.\n",
    "\n",
    "This approach of content based filtering can be extendend to increase the model performance by adding some more features like genres, cast, crew etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "AdEeBvSf24GE",
    "outputId": "6dfc4ef6-f4b3-45d3-e6b1-35e2132a2375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "original_title\n",
       "Toy Story                      Led by Woody, Andy's toys live happily in his ...\n",
       "Jumanji                        When siblings Judy and Peter discover an encha...\n",
       "Grumpier Old Men               A family wedding reignites the ancient feud be...\n",
       "Waiting to Exhale              Cheated on, mistreated and stepped on, the wom...\n",
       "Father of the Bride Part II    Just when George Banks has recovered from his ...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view sample movie descriptions\n",
    "movie_metadata['overview'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiiwYdQj24GG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21604x48083 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 574154 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tf-idf matrix for text comparison\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(movie_metadata['overview'])\n",
    "tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.01538454, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.01538454, 1.        , 0.04685421, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.04685421, 1.        , ..., 0.        , 0.00710093,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.00710093, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity between all movie-descriptions\n",
    "similarity = cosine_similarity(tfidf_matrix)\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "id": "VU3Kr_OJ24GK",
    "outputId": "b6224e65-ad8d-4634-a896-c5f9676f7a00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Toy Story</th>\n",
       "      <th>Jumanji</th>\n",
       "      <th>Grumpier Old Men</th>\n",
       "      <th>Waiting to Exhale</th>\n",
       "      <th>Father of the Bride Part II</th>\n",
       "      <th>Heat</th>\n",
       "      <th>Sabrina</th>\n",
       "      <th>Tom and Huck</th>\n",
       "      <th>Sudden Death</th>\n",
       "      <th>GoldenEye</th>\n",
       "      <th>...</th>\n",
       "      <th>The Final Storm</th>\n",
       "      <th>In a Heartbeat</th>\n",
       "      <th>Bloed, Zweet en Tranen</th>\n",
       "      <th>To Be Fat Like Me</th>\n",
       "      <th>Cadet Kelly</th>\n",
       "      <th>L'Homme à la tête de caoutchouc</th>\n",
       "      <th>Le locataire diabolique</th>\n",
       "      <th>L'Homme orchestre</th>\n",
       "      <th>Maa</th>\n",
       "      <th>Robin Hood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Toy Story</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015385</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jumanji</th>\n",
       "      <td>0.015385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grumpier Old Men</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046854</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Waiting to Exhale</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016324</td>\n",
       "      <td>0.006840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Father of the Bride Part II</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012584</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Heat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sabrina</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030866</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.028344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom and Huck</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006463</td>\n",
       "      <td>0.008592</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.164136</td>\n",
       "      <td>0.071019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006162</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sudden Death</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033213</td>\n",
       "      <td>0.046349</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GoldenEye</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016266</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21604 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Toy Story   Jumanji  Grumpier Old Men  \\\n",
       "Toy Story                     1.000000  0.015385          0.000000   \n",
       "Jumanji                       0.015385  1.000000          0.046854   \n",
       "Grumpier Old Men              0.000000  0.046854          1.000000   \n",
       "Waiting to Exhale             0.000000  0.000000          0.000000   \n",
       "Father of the Bride Part II   0.000000  0.000000          0.023903   \n",
       "Heat                          0.000000  0.047646          0.000000   \n",
       "Sabrina                       0.000000  0.000000          0.000000   \n",
       "Tom and Huck                  0.000000  0.000000          0.006463   \n",
       "Sudden Death                  0.000000  0.098488          0.000000   \n",
       "GoldenEye                     0.000000  0.000000          0.000000   \n",
       "\n",
       "                             Waiting to Exhale  Father of the Bride Part II  \\\n",
       "Toy Story                             0.000000                     0.000000   \n",
       "Jumanji                               0.000000                     0.000000   \n",
       "Grumpier Old Men                      0.000000                     0.023903   \n",
       "Waiting to Exhale                     1.000000                     0.000000   \n",
       "Father of the Bride Part II           0.000000                     1.000000   \n",
       "Heat                                  0.007417                     0.000000   \n",
       "Sabrina                               0.000000                     0.030866   \n",
       "Tom and Huck                          0.008592                     0.000000   \n",
       "Sudden Death                          0.000000                     0.033213   \n",
       "GoldenEye                             0.000000                     0.000000   \n",
       "\n",
       "                                 Heat   Sabrina  Tom and Huck  Sudden Death  \\\n",
       "Toy Story                    0.000000  0.000000      0.000000      0.000000   \n",
       "Jumanji                      0.047646  0.000000      0.000000      0.098488   \n",
       "Grumpier Old Men             0.000000  0.000000      0.006463      0.000000   \n",
       "Waiting to Exhale            0.007417  0.000000      0.008592      0.000000   \n",
       "Father of the Bride Part II  0.000000  0.030866      0.000000      0.033213   \n",
       "Heat                         1.000000  0.000000      0.000000      0.046349   \n",
       "Sabrina                      0.000000  1.000000      0.000000      0.000000   \n",
       "Tom and Huck                 0.000000  0.000000      1.000000      0.000000   \n",
       "Sudden Death                 0.046349  0.000000      0.000000      1.000000   \n",
       "GoldenEye                    0.000000  0.000000      0.000000      0.000000   \n",
       "\n",
       "                             GoldenEye  ...  The Final Storm  In a Heartbeat  \\\n",
       "Toy Story                          0.0  ...         0.000000        0.023356   \n",
       "Jumanji                            0.0  ...         0.000000        0.000000   \n",
       "Grumpier Old Men                   0.0  ...         0.000000        0.000000   \n",
       "Waiting to Exhale                  0.0  ...         0.028460        0.000000   \n",
       "Father of the Bride Part II        0.0  ...         0.000000        0.000000   \n",
       "Heat                               0.0  ...         0.000000        0.000000   \n",
       "Sabrina                            0.0  ...         0.000000        0.000000   \n",
       "Tom and Huck                       0.0  ...         0.164136        0.071019   \n",
       "Sudden Death                       0.0  ...         0.000000        0.000000   \n",
       "GoldenEye                          1.0  ...         0.043867        0.000000   \n",
       "\n",
       "                             Bloed, Zweet en Tranen  To Be Fat Like Me  \\\n",
       "Toy Story                                       0.0           0.000000   \n",
       "Jumanji                                         0.0           0.004192   \n",
       "Grumpier Old Men                                0.0           0.000000   \n",
       "Waiting to Exhale                               0.0           0.000000   \n",
       "Father of the Bride Part II                     0.0           0.022816   \n",
       "Heat                                            0.0           0.000000   \n",
       "Sabrina                                         0.0           0.028344   \n",
       "Tom and Huck                                    0.0           0.000000   \n",
       "Sudden Death                                    0.0           0.000000   \n",
       "GoldenEye                                       0.0           0.000000   \n",
       "\n",
       "                             Cadet Kelly  L'Homme à la tête de caoutchouc  \\\n",
       "Toy Story                            0.0                         0.000000   \n",
       "Jumanji                              0.0                         0.014642   \n",
       "Grumpier Old Men                     0.0                         0.015409   \n",
       "Waiting to Exhale                    0.0                         0.000000   \n",
       "Father of the Bride Part II          0.0                         0.000000   \n",
       "Heat                                 0.0                         0.000000   \n",
       "Sabrina                              0.0                         0.000000   \n",
       "Tom and Huck                         0.0                         0.000000   \n",
       "Sudden Death                         0.0                         0.000000   \n",
       "GoldenEye                            0.0                         0.076444   \n",
       "\n",
       "                             Le locataire diabolique  L'Homme orchestre  \\\n",
       "Toy Story                                   0.000000           0.000000   \n",
       "Jumanji                                     0.000000           0.000000   \n",
       "Grumpier Old Men                            0.000000           0.000000   \n",
       "Waiting to Exhale                           0.016324           0.006840   \n",
       "Father of the Bride Part II                 0.000000           0.000000   \n",
       "Heat                                        0.015837           0.000000   \n",
       "Sabrina                                     0.105139           0.000000   \n",
       "Tom and Huck                                0.000000           0.000000   \n",
       "Sudden Death                                0.000000           0.000000   \n",
       "GoldenEye                                   0.000000           0.016266   \n",
       "\n",
       "                                  Maa  Robin Hood  \n",
       "Toy Story                    0.000000         0.0  \n",
       "Jumanji                      0.000000         0.0  \n",
       "Grumpier Old Men             0.007101         0.0  \n",
       "Waiting to Exhale            0.000000         0.0  \n",
       "Father of the Bride Part II  0.012584         0.0  \n",
       "Heat                         0.000000         0.0  \n",
       "Sabrina                      0.000000         0.0  \n",
       "Tom and Huck                 0.006162         0.0  \n",
       "Sudden Death                 0.014963         0.0  \n",
       "GoldenEye                    0.000000         0.0  \n",
       "\n",
       "[10 rows x 21604 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute cosine similarity between all movie-descriptions\n",
    "similarity = cosine_similarity(tfidf_matrix)\n",
    "similarity_df = pd.DataFrame(similarity, \n",
    "                             index=movie_metadata.index.values, \n",
    "                             columns=movie_metadata.index.values)\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "Tm2sEuOs24GN",
    "outputId": "8d53fd80-f9cd-40bf-8446-e4d5651eac9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top Recommended Movies for: Batman Begins are:-\n",
      " ['Batman Unmasked: The Psychology of the Dark Knight'\n",
      " 'Batman: The Dark Knight Returns, Part 1' 'Batman: Bad Blood'\n",
      " 'Batman: Year One' 'Batman: Under the Red Hood'\n",
      " 'Batman Beyond: The Movie' 'Batman Forever'\n",
      " 'Batman: Mask of the Phantasm' 'Batman & Bill' 'Batman']\n"
     ]
    }
   ],
   "source": [
    "# movie list \n",
    "movie_list = similarity_df.columns.values\n",
    "\n",
    "\n",
    "# sample movie\n",
    "movie = 'Batman Begins'\n",
    "\n",
    "# top recommendation movie count\n",
    "top_n = 10\n",
    "\n",
    "# get movie similarity records\n",
    "movie_sim = similarity_df[similarity_df.index == movie].values[0]\n",
    "\n",
    "# get movies sorted by similarity\n",
    "sorted_movie_ids = np.argsort(movie_sim)[::-1]\n",
    "\n",
    "# get recommended movie names\n",
    "recommended_movies = movie_list[sorted_movie_ids[1:top_n+1]]\n",
    "\n",
    "print('\\n\\nTop Recommended Movies for:', movie, 'are:-\\n', recommended_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "50vzONVBqkTu"
   },
   "source": [
    "__Your turn:__ Create a function as defined below, __`content_movie_recommender()`__ which can take in sample movie names and print a list of top N recommended movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5cyFCvp24GT"
   },
   "outputs": [],
   "source": [
    "def content_movie_recommender(input_movie, similarity_database=similarity_df, movie_database_list=movie_list, top_n=10):\n",
    "    # get movie similarity records\n",
    "    movie_sim = similarity_database[similarity_database.index == input_movie].values[0]\n",
    "\n",
    "    # get movies sorted by similarity\n",
    "    sorted_movie_ids = np.argsort(movie_sim)[::-1]\n",
    "\n",
    "    # get recommended movie names\n",
    "    recommended_movies = movie_database_list[sorted_movie_ids[1:top_n+1]]\n",
    "\n",
    "    print('\\n\\nTop Recommended Movies for:', input_movie, 'are:-\\n', recommended_movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Your turn:__ Test your function below on the given sample movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top Recommended Movies for: Captain America are:-\n",
      " ['Iron Man & Captain America: Heroes United'\n",
      " 'Captain America: The First Avenger' 'Team Thor' 'Education for Death'\n",
      " 'Captain America: The Winter Soldier' '49th Parallel' 'Ultimate Avengers'\n",
      " 'Philadelphia Experiment II' 'Vice Versa' 'The Lair of the White Worm']\n",
      "\n",
      "\n",
      "Top Recommended Movies for: The Terminator are:-\n",
      " ['Terminator 2: Judgment Day' 'Terminator Salvation'\n",
      " 'Terminator 3: Rise of the Machines' 'Silent House' 'They Wait'\n",
      " 'Another World' 'Teenage Caveman' 'Appleseed Alpha' 'Respire'\n",
      " 'Just Married']\n",
      "\n",
      "\n",
      "Top Recommended Movies for: The Exorcist are:-\n",
      " ['Exorcist II: The Heretic' 'Domestic Disturbance' 'Damien: Omen II'\n",
      " 'The Exorcist III' 'Like Sunday, Like Rain' 'People Like Us'\n",
      " 'Quand on a 17 Ans' \"Don't Knock Twice\" 'Zero Day' 'Brick Mansions']\n",
      "\n",
      "\n",
      "Top Recommended Movies for: The Hunger Games: Mockingjay - Part 1 are:-\n",
      " ['The Hunger Games: Catching Fire' 'The Hunger Games: Mockingjay - Part 2'\n",
      " 'Last Train from Gun Hill' 'The Hunger Games'\n",
      " 'Will Success Spoil Rock Hunter?' 'Circumstance' 'Man of Steel'\n",
      " 'The Amityville Horror' 'Pregnancy Pact' 'Bananas']\n",
      "\n",
      "\n",
      "Top Recommended Movies for: The Blair Witch Project are:-\n",
      " ['Book of Shadows: Blair Witch 2' 'Freakonomics' 'Le Bal des actrices'\n",
      " 'Greystone Park' 'Willow Creek' 'Addio zio Tom' 'The Conspiracy'\n",
      " 'A Haunted House' 'Tonight She Comes' 'Curse of the Blair Witch']\n"
     ]
    }
   ],
   "source": [
    "sample_movies = ['Captain America', 'The Terminator', 'The Exorcist', \n",
    "                 'The Hunger Games: Mockingjay - Part 1', 'The Blair Witch Project']\n",
    "                 \n",
    "for movie_name in sample_movies:\n",
    "    content_movie_recommender(movie_name, similarity_df, movie_list, top_n=10)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Recommendation_Systems.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
